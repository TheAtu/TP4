{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import Libraries #####\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm    \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,KFold \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,roc_curve, roc_auc_score, RocCurveDisplay, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2,3,4,5,6]\n",
    "b = [1,2,3,4,5,6,7]\n",
    "c = [0,1,2,3,4,5,6]\n",
    "outliers = ['a','b','c']\n",
    "\n",
    "d = pd.DataFrame({'a':a,'b':b,'c':c})\n",
    "qs = d.quantile(.25)\n",
    "for i in range(0,len(qs)):\n",
    "  col = outliers[i]\n",
    "  q = qs[i]\n",
    "  outlier_rows = (d[col] <= q)\n",
    "  print(outlier_rows)\n",
    "  d = d[~outlier_rows]\n",
    "  print(d)\n",
    "  print()\n",
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tst(models_included=None):\n",
    "  \n",
    "  if models_included is None:\n",
    "    print('No models included')\n",
    "    return None\n",
    "\n",
    "  resultados_modelos = {}\n",
    "  for modelo in models_included:\n",
    "    model_name = modelo.__class__.__name__\n",
    "    mejor_hiperparametro = None\n",
    "\n",
    "    if model_name not in resultados_modelos.keys():\n",
    "      resultados_modelos[model_name] = {\n",
    "        'mejor_hiperparametro':{},\n",
    "        'ecm_promedios_por_hiperparametros':{}\n",
    "        }\n",
    "\n",
    "    for hiperparametro in hiperparametros:\n",
    "      if model_name != 'LogisticRegression':\n",
    "        C = 1 / hiperparametro  \n",
    "      else:\n",
    "        C = hiperparametro\n",
    "        \n",
    "      modelo.C = C\n",
    "\n",
    "      ecm_scores, ecm_promedio = cross_validation_simulated(modelo)\n",
    "      resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][hiperparametro] = ecm_promedio\n",
    "\n",
    "    resultados_modelos[model_name]['mejor_hiperparametro']['valor'] = min(\n",
    "        resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'],\n",
    "        key=lambda x: resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][x]\n",
    "    )\n",
    "    resultados_modelos[model_name]['mejor_hiperparametro']['ecm_promedio'] = resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'].get(resultados_modelos[model_name]['mejor_hiperparametro']['valor'])\n",
    "\n",
    "\n",
    "  return resultados_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_simulated(modelo, standard=True, **args):\n",
    "  print('===========')\n",
    "  print('modelo:', modelo)\n",
    "  print('len Modelo Name:', len(modelo.__class__.__name__))\n",
    "  # print('C:', modelo.C, int(modelo.C * 100))\n",
    "\n",
    "  seed = len(modelo.__class__.__name__) #+ int(modelo.C * 100)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  # Generate two random numbers\n",
    "  random_number_1 = np.random.rand()\n",
    "  random_number_2 = np.random.rand()\n",
    "\n",
    "  return random_number_1, random_number_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "modelo: LogisticRegression(C=0.08333333333333333)\n",
      "len Modelo Name: 18\n",
      "C: 0.08333333333333333 8\n",
      "===========\n",
      "modelo: LogisticRegression()\n",
      "len Modelo Name: 18\n",
      "C: 1.0 100\n",
      "===========\n",
      "modelo: LogisticRegression(C=0.5)\n",
      "len Modelo Name: 18\n",
      "C: 0.5 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'mejor_hiperparametro': {'valor': 2,\n",
       "   'ecm_promedio': 0.043361051161900255},\n",
       "  'ecm_promedios_por_hiperparametros': {12: 0.5193914793053007,\n",
       "   1: 0.5791378929947867,\n",
       "   2: 0.043361051161900255}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst(models_included = [LogisticRegression()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "modelo: LogisticRegression(C=0.08333333333333333)\n",
      "len Modelo Name: 18\n",
      "C: 0.08333333333333333 8\n",
      "===========\n",
      "modelo: LogisticRegression()\n",
      "len Modelo Name: 18\n",
      "C: 1.0 100\n",
      "===========\n",
      "modelo: LogisticRegression(C=0.5)\n",
      "len Modelo Name: 18\n",
      "C: 0.5 50\n",
      "################\n",
      "{'LogisticRegression': {'mejor_hiperparametro': 2, 'ecm_promedios_por_hiperparametros': {12: 0.5193914793053007, 1: 0.5791378929947867, 2: 0.043361051161900255}}}\n",
      "################\n"
     ]
    }
   ],
   "source": [
    "models_included = [LogisticRegression()]\n",
    "hiperparametros = [12,1,2]\n",
    "\n",
    "resultados_modelos = {}\n",
    "for modelo in models_included:\n",
    "    model_name = modelo.__class__.__name__\n",
    "    mejor_hiperparametro = None\n",
    "    if model_name not in resultados_modelos.keys():\n",
    "      resultados_modelos[model_name] = {\n",
    "        'mejor_hiperparametro':{},\n",
    "        'ecm_promedios_por_hiperparametros':{}\n",
    "        }\n",
    "\n",
    "    for hiperparametro in hiperparametros:\n",
    "      C = 1 / hiperparametro\n",
    "      modelo.C = C\n",
    "\n",
    "      ecm_scores, ecm_promedio = cv(modelo)\n",
    "      resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][hiperparametro] = ecm_promedio\n",
    "\n",
    "    resultados_modelos[model_name]['mejor_hiperparametro'] = min(\n",
    "        resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'],\n",
    "        key=lambda x: resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][x]\n",
    "    )\n",
    "print('################')\n",
    "print(resultados_modelos)\n",
    "print('################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: 0.5193914793053007, 1: 0.5791378929947867, 2: 0.043361051161900255}\n",
      "{'LogisticRegression': {'mejor_hiperparametro': 2, 'ecm_promedios_por_hiperparametros': {12: 0.5193914793053007, 1: 0.5791378929947867, 2: 0.043361051161900255}}}\n"
     ]
    }
   ],
   "source": [
    "print(resultados_modelos['LogisticRegression']['ecm_promedios_por_hiperparametros'])\n",
    "print(resultados_modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "print(LogisticRegression().__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_config(X, Y, K, models_and_configs =[[None,None]]):\n",
    "  models_included\n",
    "  if models_included is None:\n",
    "    print('No models included')\n",
    "    return None\n",
    "\n",
    "  if models_included[] is None:\n",
    "    print('No models included')\n",
    "    return None\n",
    "\n",
    "  resultados_modelos = {}\n",
    "  for modelo in models_included:\n",
    "    model_name = modelo.__class__.__name__\n",
    "    mejor_hiperparametro = None\n",
    "\n",
    "    if model_name not in resultados_modelos.keys():\n",
    "      resultados_modelos[model_name] = {\n",
    "        'mejor_hiperparametro':{},\n",
    "        'ecm_promedios_por_hiperparametros':{}\n",
    "        }\n",
    "\n",
    "    for hiperparametro in hiperparametros:\n",
    "      C = 1 / hiperparametro  \n",
    "      hiperparametro\n",
    "        \n",
    "      modelo.X = X\n",
    "      modelo.Y = Y\n",
    "      modelo.K = K\n",
    "\n",
    "      ecm_scores, ecm_promedio = cross_validation_simulated(modelo, standard=True)\n",
    "      resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][hiperparametro] = ecm_promedio\n",
    "\n",
    "    resultados_modelos[model_name]['mejor_hiperparametro'] = min(\n",
    "        resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'],\n",
    "        key=lambda x: resultados_modelos[model_name]['ecm_promedios_por_hiperparametros'][x]\n",
    "    )\n",
    "\n",
    "  return resultados_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evalua_config() missing 1 required positional argument: 'hiperparametros'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m hiperparametros_2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      3\u001b[0m hiperparametros_3 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mevalua_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_included\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhiperparametros_1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDecisionTreeRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhiperparametro\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhiperparametros_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhiperparametro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhiperparametros_3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: evalua_config() missing 1 required positional argument: 'hiperparametros'"
     ]
    }
   ],
   "source": [
    "hiperparametros_1 = [0.1,0.2,0.3]\n",
    "hiperparametros_2 = [1,2,3]\n",
    "hiperparametros_3 = [1,2,3]\n",
    "\n",
    "evalua_config(X=1, Y=1, K=1, models_included={\n",
    "  LogisticRegression(C=C, penalty=1, solver= 'saga', max_iter = 100): hiperparametros_1,\n",
    "  DecisionTreeRegressor(max_depth = hiperparametro): hiperparametros_2,\n",
    "  RandomForestRegressor(n_estimators=1, max_samples=200, max_features=hiperparametro, random_state=1): hiperparametros_3,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.5, penalty=1, solver='saga')\n",
      "LogisticRegression\n",
      "[0.1, 0.2, 0.3]\n",
      "DecisionTreeRegressor(max_depth=2)\n",
      "DecisionTreeRegressor\n",
      "[1, 2, 3]\n",
      "RandomForestRegressor(max_features=2, max_samples=200, n_estimators=1,\n",
      "                      random_state=1)\n",
      "RandomForestRegressor\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "  LogisticRegression(C=C, penalty=1, solver= 'saga', max_iter = 100) : hiperparametros_1,\n",
    "  DecisionTreeRegressor(max_depth = hiperparametro): hiperparametros_2,\n",
    "  RandomForestRegressor(n_estimators=1, max_samples=200, max_features=hiperparametro, random_state=1): hiperparametros_2\n",
    "}\n",
    "\n",
    "def test(models_and_configs = None):\n",
    "  models_included = []\n",
    "  for model in models_and_configs.keys():\n",
    "    print(model)\n",
    "    print(model.__class__.__name__)\n",
    "    print(models_and_configs[model])\n",
    "test(models_and_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTreeRegressor()\n",
    "a.max_depth = 4\n",
    "a.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from ISLP import load_data\n",
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_multiples_metodos(K, X_train, X_test, Y_train, Y_test, X, Y, hiperparametro, k_knn, modelos=None):\n",
    "  '''\n",
    "  Esta función lo que hace es que para una lista de posibles modelos, le aplica la función evalua_metodos a cada uno de los\n",
    "  elementos de la lista. Luego genera una lista de resultados asociados a lo que hace la función evalua_metodo y los adjunta\n",
    "  en una tabla que dicho sea de paso es el return del modelo en el que podemos aprecias distintas metricas para cada modelo.\n",
    "  '''\n",
    "  if modelos:\n",
    "    print('No models were provided')\n",
    "    return None\n",
    "\n",
    "  tabla_comparativa = pd.DataFrame(columns=[\"Modelo\", \"Hiperparametro\", \"Accuracy\", \"AUC\", \"Precision\", \"Specificity\", \"Recall\", \"ECM\"])\n",
    "  \n",
    "  for modelo in modelos:\n",
    "    metricas_log = evalua_metodo(modelo, X_train, X_test, Y_train, Y_test)\n",
    "    resultados = [\n",
    "      modelo,\n",
    "      hiperparametro,\n",
    "      metricas_log['accuracy'][0],\n",
    "      metricas_log['auc'][0],\n",
    "      metricas_log['precision'][0],\n",
    "      metricas_log['specificity'][0],\n",
    "      metricas_log['recall'][0],\n",
    "      metricas_log['ecm'][0]\n",
    "      ]\n",
    "      \n",
    "    tabla_comparativa.loc[len(tabla_comparativa)] = resultados\n",
    "\n",
    "  return tabla_comparativa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJEMPLO DE USO! checkear k_nn, n_estimators, etc\n",
    "'''\n",
    "evalua_multiples_metodos(\n",
    "  K=1,\n",
    "  X_train, X_test,\n",
    "  Y_train, Y_test, \n",
    "  X, Y,\n",
    "  hiperparametro=1,\n",
    "  k_knn=1, #?\n",
    "  modelos=[\n",
    "    DecisionTreeRegressor(max_depth=7),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    KNeighborsClassifier(n_neighbors=k_knn),\n",
    "    LogisticRegression(C=1 / hiperparametro, penalty=penalty, solver='saga'),\n",
    "    RandomForest(n_estimators=n_estimators, max_samples=200, max_features=9, random_state=1),\n",
    "    GradientBoostingRegressor(n_estimators=n_estimators, max_depth=9, random_state=1),\n",
    "    BaggingRegressor(n_estimators=n_estimators, max_samples=200, random_state=1)\n",
    "  ]\n",
    ")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('pyEnv-Tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c624079bdbcdf559a5caa27822ba1284677e01b949e217d00eab1893de7b1b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
